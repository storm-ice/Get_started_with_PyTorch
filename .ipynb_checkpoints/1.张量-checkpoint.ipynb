{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4048d9d8-fb39-4410-b0cf-10318668b683",
   "metadata": {},
   "source": [
    "张量 — PyTorch 教程 2.2.0+cu121 文档\n",
    "\n",
    "[张量 — PyTorch 教程 2.2.0+cu121 文档](https://pytorch.org/tutorials/beginner/basics/tensorqs_tutorial.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd44ba8f-f014-4e56-8b47-633f93267c14",
   "metadata": {},
   "source": [
    "# 张量"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b39b10d-c10d-41aa-bedd-f9108db7bd8b",
   "metadata": {},
   "source": [
    "张量是一种特殊的数据结构，与数组和矩阵非常相似。在 PyTorch 中，我们使用张量对模型的输入和输出以及模型的参数进行编码。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a943cc-5621-49e9-9bc9-1b4db913728e",
   "metadata": {},
   "source": [
    "[张量与NumPy 的](https://numpy.org/)ndarray类似，不同之处在于张量可以在 GPU 或其他硬件加速器上运行。事实上，张量和 NumPy 数组通常可以共享相同的底层内存，从而无需复制数据（请参阅[Bridge with NumPy](https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html#bridge-to-np-label)）。[张量还针对自动微分进行了优化（稍后我们将在Autograd](https://pytorch.org/tutorials/beginner/basics/autogradqs_tutorial.html)部分中了解更多相关内容 ）。如果您熟悉 ndarrays，那么您就会熟悉 Tensor API。如果没有，那就跟随吧！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "410916c2-6e55-43ee-b729-c0592b17a479",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10f27d1-dbce-4732-8ad8-8b8a29a1541f",
   "metadata": {},
   "source": [
    "# 初始化张量"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0cdd34-dd53-4e04-9e7b-0f301439d10c",
   "metadata": {},
   "source": [
    "张量可以通过多种方式初始化。看看下面的例子："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7fe135-bd1a-4dec-959d-b928f11eb802",
   "metadata": {},
   "source": [
    "# 直接来自数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584f4dbd-eade-415c-9879-aa207945620d",
   "metadata": {},
   "source": [
    "张量可以直接从数据创建。数据类型是自动推断的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f351f965-2ac6-406e-9ffb-b3043e544caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2], [3, 4]]\n",
      "tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "data = [[1,2],[3,4]]\n",
    "x_data = torch.tensor(data)\n",
    "print(data)\n",
    "print(x_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b3c8db-e882-4dd1-845f-f0d9fd711e5c",
   "metadata": {},
   "source": [
    "## 来自 NumPy 数组"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ad9215-80f2-4993-821f-8f5d0fe47a5c",
   "metadata": {},
   "source": [
    "张量可以从 NumPy 数组创建（反之亦然 - 请参阅[Bridge with NumPy](https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html#bridge-to-np-label)）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94ad7c7f-32bd-48f0-85a0-13cae0b60c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]]\n",
      "tensor([[1, 2],\n",
      "        [3, 4]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "np_array = np.array(data)\n",
    "np = torch.from_numpy(np_array)\n",
    "print(np_array)\n",
    "print(np)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c801b9-91e4-4d6d-85ab-900a4449c7ee",
   "metadata": {},
   "source": [
    "## 从另一个张量："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598a168a-41a6-4e68-a512-d95ced5a660d",
   "metadata": {},
   "source": [
    "新张量保留参数张量的属性（形状、数据类型），除非显式覆盖。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e880b86b-58f8-48d5-bb7a-90eb3d7b3969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones Tensor: \n",
      " tensor([[1, 1],\n",
      "        [1, 1]]) \n",
      "\n",
      "Random Tensor: \n",
      " tensor([[0.7857, 0.4832],\n",
      "        [0.7416, 0.1409]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_ones = torch.ones_like(x_data) \n",
    "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
    "\n",
    "x_rand = torch.rand_like(x_data, dtype = torch.float)\n",
    "print(f\"Random Tensor: \\n {x_rand} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c00608e-4837-4733-9e86-69216ebf4a2c",
   "metadata": {},
   "source": [
    "## 使用随机值或常数值："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ffc027-d677-4e06-82b2-f5aa82d2fc88",
   "metadata": {},
   "source": [
    "`shape`是张量维度的元组。在下面的函数中，它确定输出张量的维数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fd2682c-62a3-4cc1-8cf3-08912d08e645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor: \n",
      " tensor([[0.4988, 0.3013, 0.3649],\n",
      "        [0.0315, 0.0929, 0.3961]]) \n",
      "\n",
      "Ones Tensor: \n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]]) \n",
      "\n",
      "zeros Tensor: \n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "shape = (2, 3, )\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "\n",
    "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
    "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
    "print(f\"zeros Tensor: \\n {zeros_tensor} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28580c47-c3ba-4844-a471-d20bb1720e92",
   "metadata": {},
   "source": [
    "# 张量的属性"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1de6d2c-57a4-476d-9ae0-a868ccb8cb90",
   "metadata": {},
   "source": [
    "张量属性描述了它们的形状、数据类型以及存储它们的设备。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a312b2ab-95f0-4e2f-b640-7a086943605e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(3, 4)\n",
    "\n",
    "print(f\"Shape of tensor: {tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0326ddd1-b28e-4707-ab8d-43e469e519e0",
   "metadata": {},
   "source": [
    "# 张量运算"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de16c220-745c-4a40-88e7-1d225c18987c",
   "metadata": {},
   "source": [
    "[这里](https://pytorch.org/docs/stable/torch.html)全面描述了 100 多种张量运算，包括算术、线性代数、矩阵操作（转置、索引、切片）、采样等。\r\n",
    "\r\n",
    "这些操作中的每一个都可以在 GPU 上运行（速度通常高于 CPU）。如果您使用 Colab，请通过转至运行时 > 更改运行时类型 > GPU 来分配 GPU。\r\n",
    "\r\n",
    "默认情况下，张量是在 CPU 上创建的。我们需要使用 `.to`方法显式地将张量移动到 GPU（在检查 GPU 可用性之后）。请记住，跨设备复制大张量在时间和内存方面可能会很昂贵！ory!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09922019-83f4-40c7-8f34-4eb4a0849957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We move our tensor to the GPU if available\n",
    "if torch.cuda.is_available():\n",
    "    tensor = tensor.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac38f69-74f1-4666-b876-17502ee515f7",
   "metadata": {},
   "source": [
    "尝试列表中的一些操作。如果您熟悉 NumPy API，您会发现 Tensor API 使用起来非常简单。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c9fd12-8fad-4229-a52a-964cce5a3b56",
   "metadata": {},
   "source": [
    "## 标准的类似 numpy 的索引和切片："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "244382dd-36d8-4cb2-b585-c3cf9964de36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones Tensor:\n",
      " tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]]) \n",
      "\n",
      "First row: tensor([1., 1., 1., 1.])\n",
      "First column: tensor([1., 1., 1., 1.])\n",
      "Last column: tensor([1., 1., 1., 1.])\n",
      "Ones Tensor:\n",
      " tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.ones(4, 4)\n",
    "print(f\"Ones Tensor:\\n {tensor} \\n\") \n",
    "print(f\"First row: {tensor[0]}\")\n",
    "print(f\"First column: {tensor[:, 0]}\")\n",
    "print(f\"Last column: {tensor[..., -1]}\")\n",
    "tensor[:,1] = 0\n",
    "print(f\"Ones Tensor:\\n {tensor} \\n\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b4db36-4442-4e09-b32c-7f0c7fc18770",
   "metadata": {},
   "source": [
    "## 连接张量"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02b3774-4799-4f28-bb9e-2d6ed9ae77f2",
   "metadata": {},
   "source": [
    "**连接张量**您可以使用它`torch.cat`来沿给定维度连接一系列张量。另请参见[torch.stack](https://pytorch.org/docs/stable/generated/torch.stack.html)，这是另一个与 略有不同的张量连接运算符`torch.cat`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65de2a34-9145-46be-ba94-ddfc7fb71a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.cat([tensor, tensor, tensor], dim = 1)\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53c195c-54b3-4936-a3ec-deda934902ed",
   "metadata": {},
   "source": [
    "## 算术运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5a1c1f6-144f-4ee8-a16c-2241a5c96af8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This computes the matrix multiplication between two tensors. y1, y2, y3 will have the same value\n",
    "# ``tensor.T`` returns the transpose of a tensor\n",
    "y1 = tensor @ tensor.T\n",
    "y2 = tensor.matmul(tensor.T)\n",
    "\n",
    "y3 = torch.rand_like(y1)\n",
    "torch.matmul(tensor, tensor.T, out=y3)\n",
    "\n",
    "# This computes the element-wise product. z1, z2, z3 will have the same value\n",
    "z1 = tensor * tensor\n",
    "z2 = tensor.mul(tensor)\n",
    "\n",
    "z3 = torch.rand_like(tensor)\n",
    "torch.mul(tensor, tensor, out = z3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b126100-528a-4b03-8b6b-bc843b7f2fe1",
   "metadata": {},
   "source": [
    "## 单元素张量"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4316cf3-c4da-440f-b4b0-d74d0b5dcac0",
   "metadata": {},
   "source": [
    "**单元素张量**如果您有一个单元素张量，例如通过将张量的所有值聚合为一个值，您可以使用以下方法将其转换为 Python 数值`item()`："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4fec5a12-4e10-4549-b523-0032162be3e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.0 <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "agg = tensor.sum()\n",
    "agg_item = agg.item()\n",
    "print(agg_item, type(agg_item))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7ac4ad-997e-4090-b8bd-e75f365055c1",
   "metadata": {},
   "source": [
    "## 就地运算"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174cd8f2-7d64-4c35-9830-65deda3656b5",
   "metadata": {},
   "source": [
    " **就地运算** 将结果存储到操作数中的操作称为就地运算。它们由`_`后缀表示。例如：`x.copy_(y)`、`x.t_()`、 将会改变`x`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cfbd0631-0512-453e-8569-22dcba2089a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]]) \n",
      "\n",
      "tensor([[6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"{tensor} \\n\")\n",
    "tensor.add_(5)\n",
    "print(f\"{tensor} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4483fb9e-523d-49bb-867f-472df439cf52",
   "metadata": {},
   "source": [
    "### 笔记"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12954e3-455d-4f28-8eca-ab6ce126255a",
   "metadata": {},
   "source": [
    "\r\n",
    "就地操作可以节省一些内存，但在计算导数时可能会出现问题，因为历史记录会立即丢失。因此，不鼓励使用它们。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9fee54-37a1-4ee1-a42d-4e9c89a1e3f8",
   "metadata": {},
   "source": [
    "# 与 NumPy 的桥梁"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce450d87-902d-4215-8680-b82d2eb337d5",
   "metadata": {},
   "source": [
    "CPU 和 NumPy 数组上的张量可以共享其底层内存位置，改变其中一个就会改变另一个。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3cbbc0-5441-43e4-8521-ab3646da5632",
   "metadata": {},
   "source": [
    "## 张量到 NumPy 数组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5419e768-9b8a-4186-a451-716a49378bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([1., 1., 1., 1., 1.])\n",
      "n: [1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "t = torch.ones(5)\n",
    "print(f\"t: {t}\")\n",
    "n = t.numpy()\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de0cf38-a874-41cb-83db-c8bb9a3c9026",
   "metadata": {},
   "source": [
    "张量的变化反映在 NumPy 数组中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a86ff10a-0b39-44cd-ba58-12e42345d12f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([2., 2., 2., 2., 2.])\n",
      "n: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "t.add_(1)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814ddc18-178c-4c15-b9f8-0d1518a4fb9a",
   "metadata": {},
   "source": [
    "## NumPy 数组到张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b3c5ebc5-c15b-42ec-977d-eea13b4ded61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n: [1. 1. 1. 1. 1.]\n",
      "n: tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "n = np.ones(5)\n",
    "t = torch.from_numpy(n)\n",
    "print(f\"n: {n}\")\n",
    "print(f\"t: {t}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59488a43-a2bd-46b6-a109-b643325dce75",
   "metadata": {},
   "source": [
    "NumPy 数组中的变化反映在张量中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "efc44b2c-4fb4-4f5e-89a1-0a692b2c6638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n: [2. 2. 2. 2. 2.]\n",
      "t: tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "np.add(n, 1, out = n)\n",
    "print(f\"n: {n}\")\n",
    "print(f\"t: {t}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116705f2-f3fd-4ff3-badc-ab59396602e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
